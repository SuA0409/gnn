{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hiBuRD--j9tR",
        "outputId": "7edd696c-f2a0-4260-e251-287afc9d9d80"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.8.0+cpu\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution ~orch-geometric (C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages)\n",
            "  error: subprocess-exited-with-error\n",
            "  \n",
            "  × Getting requirements to build wheel did not run successfully.\n",
            "  │ exit code: 1\n",
            "  ╰─> [23 lines of output]\n",
            "      Traceback (most recent call last):\n",
            "        File \u001b[35m\"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\"\u001b[0m, line \u001b[35m389\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
            "          \u001b[31mmain\u001b[0m\u001b[1;31m()\u001b[0m\n",
            "          \u001b[31m~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
            "        File \u001b[35m\"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\"\u001b[0m, line \u001b[35m373\u001b[0m, in \u001b[35mmain\u001b[0m\n",
            "          json_out[\"return_val\"] = \u001b[31mhook\u001b[0m\u001b[1;31m(**hook_input[\"kwargs\"])\u001b[0m\n",
            "                                   \u001b[31m~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
            "        File \u001b[35m\"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\"\u001b[0m, line \u001b[35m143\u001b[0m, in \u001b[35mget_requires_for_build_wheel\u001b[0m\n",
            "          return hook(config_settings)\n",
            "        File \u001b[35m\"C:\\Users\\user\\AppData\\Local\\Temp\\pip-build-env-a0nhv4a9\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\"\u001b[0m, line \u001b[35m331\u001b[0m, in \u001b[35mget_requires_for_build_wheel\u001b[0m\n",
            "          return \u001b[31mself._get_build_requires\u001b[0m\u001b[1;31m(config_settings, requirements=[])\u001b[0m\n",
            "                 \u001b[31m~~~~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
            "        File \u001b[35m\"C:\\Users\\user\\AppData\\Local\\Temp\\pip-build-env-a0nhv4a9\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\"\u001b[0m, line \u001b[35m301\u001b[0m, in \u001b[35m_get_build_requires\u001b[0m\n",
            "          \u001b[31mself.run_setup\u001b[0m\u001b[1;31m()\u001b[0m\n",
            "          \u001b[31m~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
            "        File \u001b[35m\"C:\\Users\\user\\AppData\\Local\\Temp\\pip-build-env-a0nhv4a9\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\"\u001b[0m, line \u001b[35m512\u001b[0m, in \u001b[35mrun_setup\u001b[0m\n",
            "          \u001b[31msuper().run_setup\u001b[0m\u001b[1;31m(setup_script=setup_script)\u001b[0m\n",
            "          \u001b[31m~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
            "        File \u001b[35m\"C:\\Users\\user\\AppData\\Local\\Temp\\pip-build-env-a0nhv4a9\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\"\u001b[0m, line \u001b[35m317\u001b[0m, in \u001b[35mrun_setup\u001b[0m\n",
            "          \u001b[31mexec\u001b[0m\u001b[1;31m(code, locals())\u001b[0m\n",
            "          \u001b[31m~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^\u001b[0m\n",
            "        File \u001b[35m\"<string>\"\u001b[0m, line \u001b[35m8\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
            "      \u001b[1;35mModuleNotFoundError\u001b[0m: \u001b[35mNo module named 'torch'\u001b[0m\n",
            "      [end of output]\n",
            "  \n",
            "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "error: subprocess-exited-with-error\n",
            "\n",
            "× Getting requirements to build wheel did not run successfully.\n",
            "│ exit code: 1\n",
            "╰─> See above for output.\n",
            "\n",
            "note: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "WARNING: Ignoring invalid distribution ~orch-geometric (C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages)\n",
            "  error: subprocess-exited-with-error\n",
            "  \n",
            "  × Getting requirements to build wheel did not run successfully.\n",
            "  │ exit code: 1\n",
            "  ╰─> [23 lines of output]\n",
            "      Traceback (most recent call last):\n",
            "        File \u001b[35m\"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\"\u001b[0m, line \u001b[35m389\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
            "          \u001b[31mmain\u001b[0m\u001b[1;31m()\u001b[0m\n",
            "          \u001b[31m~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
            "        File \u001b[35m\"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\"\u001b[0m, line \u001b[35m373\u001b[0m, in \u001b[35mmain\u001b[0m\n",
            "          json_out[\"return_val\"] = \u001b[31mhook\u001b[0m\u001b[1;31m(**hook_input[\"kwargs\"])\u001b[0m\n",
            "                                   \u001b[31m~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
            "        File \u001b[35m\"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\"\u001b[0m, line \u001b[35m143\u001b[0m, in \u001b[35mget_requires_for_build_wheel\u001b[0m\n",
            "          return hook(config_settings)\n",
            "        File \u001b[35m\"C:\\Users\\user\\AppData\\Local\\Temp\\pip-build-env-enkvnwt4\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\"\u001b[0m, line \u001b[35m331\u001b[0m, in \u001b[35mget_requires_for_build_wheel\u001b[0m\n",
            "          return \u001b[31mself._get_build_requires\u001b[0m\u001b[1;31m(config_settings, requirements=[])\u001b[0m\n",
            "                 \u001b[31m~~~~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
            "        File \u001b[35m\"C:\\Users\\user\\AppData\\Local\\Temp\\pip-build-env-enkvnwt4\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\"\u001b[0m, line \u001b[35m301\u001b[0m, in \u001b[35m_get_build_requires\u001b[0m\n",
            "          \u001b[31mself.run_setup\u001b[0m\u001b[1;31m()\u001b[0m\n",
            "          \u001b[31m~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
            "        File \u001b[35m\"C:\\Users\\user\\AppData\\Local\\Temp\\pip-build-env-enkvnwt4\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\"\u001b[0m, line \u001b[35m512\u001b[0m, in \u001b[35mrun_setup\u001b[0m\n",
            "          \u001b[31msuper().run_setup\u001b[0m\u001b[1;31m(setup_script=setup_script)\u001b[0m\n",
            "          \u001b[31m~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
            "        File \u001b[35m\"C:\\Users\\user\\AppData\\Local\\Temp\\pip-build-env-enkvnwt4\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\"\u001b[0m, line \u001b[35m317\u001b[0m, in \u001b[35mrun_setup\u001b[0m\n",
            "          \u001b[31mexec\u001b[0m\u001b[1;31m(code, locals())\u001b[0m\n",
            "          \u001b[31m~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^\u001b[0m\n",
            "        File \u001b[35m\"<string>\"\u001b[0m, line \u001b[35m8\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
            "      \u001b[1;35mModuleNotFoundError\u001b[0m: \u001b[35mNo module named 'torch'\u001b[0m\n",
            "      [end of output]\n",
            "  \n",
            "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "error: subprocess-exited-with-error\n",
            "\n",
            "× Getting requirements to build wheel did not run successfully.\n",
            "│ exit code: 1\n",
            "╰─> See above for output.\n",
            "\n",
            "note: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "WARNING: Ignoring invalid distribution ~orch-geometric (C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~orch-geometric (C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~orch-geometric (C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "os.environ['TORCH'] = torch.__version__\n",
        "print(torch.__version__)\n",
        "\n",
        "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "vANBsaB3j9tY"
      },
      "outputs": [],
      "source": [
        "import torch_geometric\n",
        "from torch_geometric.datasets import Planetoid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "DOgYBrlJj9tZ"
      },
      "outputs": [],
      "source": [
        "use_cuda_if_available = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CQxBmTKj9tZ"
      },
      "source": [
        "# Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "HIhXNd7Vj9ta",
        "outputId": "1a3242c5-306f-4825-f1d1-9b16ec8f31a1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
            "Processing...\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "dataset = Planetoid(root=\"tutorial1\",name= \"Cora\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUdJn2m7j9tb"
      },
      "source": [
        "##### Dataset properties"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "AdeObJvPj9tb",
        "outputId": "b34a6644-b2d8-43ef-85f3-b50cbb4ac731"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cora()\n",
            "number of graphs:\t\t 1\n",
            "number of classes:\t\t 7\n",
            "number of node features:\t 1433\n",
            "number of edge features:\t 0\n"
          ]
        }
      ],
      "source": [
        "print(dataset)\n",
        "print(\"number of graphs:\\t\\t\",len(dataset))\n",
        "print(\"number of classes:\\t\\t\",dataset.num_classes)\n",
        "print(\"number of node features:\\t\",dataset.num_node_features)\n",
        "print(\"number of edge features:\\t\",dataset.num_edge_features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYEijRsbj9tc"
      },
      "source": [
        "##### Dataset shapes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "7Kk_WPESj9tc",
        "outputId": "1cc040a0-03b6-49b9-821b-6f8eef3d2afd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14764\\2657384431.py:1: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
            "  print(dataset.data)\n"
          ]
        }
      ],
      "source": [
        "print(dataset.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "wGO9Lrdsj9td",
        "outputId": "a8db6815-784f-4456-af69-75e4ba85d678"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "edge_index:\t\t torch.Size([2, 10556])\n",
            "tensor([[ 633, 1862, 2582,  ...,  598, 1473, 2706],\n",
            "        [   0,    0,    0,  ..., 2707, 2707, 2707]])\n",
            "\n",
            "\n",
            "train_mask:\t\t torch.Size([2708])\n",
            "tensor([ True,  True,  True,  ..., False, False, False])\n",
            "\n",
            "\n",
            "x:\t\t torch.Size([2708, 1433])\n",
            "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
            "\n",
            "\n",
            "y:\t\t torch.Size([2708])\n",
            "tensor([3, 4, 4,  ..., 3, 3, 3])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14764\\3217291099.py:1: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
            "  print(\"edge_index:\\t\\t\",dataset.data.edge_index.shape)\n",
            "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14764\\3217291099.py:2: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
            "  print(dataset.data.edge_index)\n",
            "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14764\\3217291099.py:5: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
            "  print(\"train_mask:\\t\\t\",dataset.data.train_mask.shape)\n",
            "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14764\\3217291099.py:6: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
            "  print(dataset.data.train_mask)\n",
            "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14764\\3217291099.py:10: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
            "  print(\"x:\\t\\t\",dataset.data.x.shape)\n",
            "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14764\\3217291099.py:11: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
            "  print(dataset.data.x)\n",
            "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14764\\3217291099.py:15: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
            "  print(\"y:\\t\\t\",dataset.data.y.shape)\n",
            "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14764\\3217291099.py:16: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
            "  print(dataset.data.y)\n"
          ]
        }
      ],
      "source": [
        "print(\"edge_index:\\t\\t\",dataset.data.edge_index.shape)\n",
        "print(dataset.data.edge_index)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"train_mask:\\t\\t\",dataset.data.train_mask.shape)\n",
        "print(dataset.data.train_mask)\n",
        "# boolen으로 표현됨: 어느 node가 train이고, val이고, test인지를 나타냄\n",
        "\n",
        "print(\"\\n\")\n",
        "print(\"x:\\t\\t\",dataset.data.x.shape)\n",
        "print(dataset.data.x)\n",
        "# x: 각 node의 feature matrix (node 개수 x feature 개수)\n",
        "\n",
        "print(\"\\n\")\n",
        "print(\"y:\\t\\t\",dataset.data.y.shape)\n",
        "print(dataset.data.y)\n",
        "# y: 각 node의 label (node 개수)\n",
        "# ex. 0번째 node의 label은 3, 1번째 node의 label은 4, ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "224XEU0Xj9td"
      },
      "outputs": [],
      "source": [
        "import os.path as osp\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import SAGEConv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ssRHZfl-j9te"
      },
      "outputs": [],
      "source": [
        "data = dataset[0]\n",
        "# only one graph in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LBf5dzvDj9te"
      },
      "outputs": [],
      "source": [
        "class Net(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        self.conv = SAGEConv(dataset.num_features,  # input feature dimension(=1433)\n",
        "                             dataset.num_classes,  # output feature dimension(=7)\n",
        "                             aggr=\"max\") # max, mean, add ...)\n",
        "\n",
        "    def forward(self):\n",
        "        x = self.conv(data.x, data.edge_index)\n",
        "        \n",
        "        return F.log_softmax(x, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "f9vOBfc5j9te",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() and use_cuda_if_available else 'cpu')\n",
        "model, data = Net().to(device), data.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "QtKyBqo_j9te",
        "outputId": "ef2ce484-f4fd-4a6d-cf69-20b3f386b635"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "RxkzIeAnj9tf"
      },
      "outputs": [],
      "source": [
        "def train():\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    F.nll_loss(model()[data.train_mask], data.y[data.train_mask]).backward()\n",
        "    optimizer.step()\n",
        "\n",
        "\n",
        "def test():\n",
        "    model.eval()\n",
        "    logits, accs = model(), []\n",
        "    for _, mask in data('train_mask', 'val_mask', 'test_mask'):\n",
        "        pred = logits[mask].max(1)[1]\n",
        "        acc = pred.eq(data.y[mask]).sum().item() / mask.sum().item()\n",
        "        accs.append(acc)\n",
        "    return accs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "0Qo3Wjldj9tf",
        "outputId": "1d97e462-f840-4578-e8a9-332918b2c688"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 010, Val: 0.7200, Test: 0.7140\n",
            "Epoch: 020, Val: 0.7200, Test: 0.7140\n",
            "Epoch: 030, Val: 0.7200, Test: 0.7140\n",
            "Epoch: 040, Val: 0.7200, Test: 0.7140\n",
            "Epoch: 050, Val: 0.7200, Test: 0.7140\n",
            "Epoch: 060, Val: 0.7200, Test: 0.7140\n",
            "Epoch: 070, Val: 0.7200, Test: 0.7140\n",
            "Epoch: 080, Val: 0.7220, Test: 0.7210\n",
            "Epoch: 090, Val: 0.7260, Test: 0.7220\n"
          ]
        }
      ],
      "source": [
        "best_val_acc = test_acc = 0\n",
        "for epoch in range(1,100):\n",
        "    train()\n",
        "    _, val_acc, tmp_test_acc = test()\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        test_acc = tmp_test_acc\n",
        "    log = 'Epoch: {:03d}, Val: {:.4f}, Test: {:.4f}'\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        print(log.format(epoch, best_val_acc, test_acc))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
